name: Scrape Shutdowns Information

on:
  schedule:
    - cron: '*/30 * * * *'  # Every 30 minutes
  workflow_dispatch:        # Allow manual trigger

concurrency:
  group: pages
  cancel-in-progress: false

jobs:
  scrape:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pages: write
      id-token: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Resolve Playwright version
        id: pw
        shell: bash
        run: |
          set -euo pipefail
          PW_VERSION="$(npm view playwright version)"
          echo "version=$PW_VERSION" >> "$GITHUB_OUTPUT"

      - name: Cache Playwright browsers
        id: pw-cache
        uses: actions/cache/restore@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-ms-playwright-${{ steps.pw.outputs.version }}

      - name: Cache npm
        id: npm-cache
        uses: actions/cache/restore@v4
        with:
          path: ~/.npm
          key: ${{ runner.os }}-npm-node20-playwright-${{ steps.pw.outputs.version }}
          restore-keys: |
            ${{ runner.os }}-npm-node20-
          
      - name: Install Playwright
        run: |
          npm install playwright@${{ steps.pw.outputs.version }}
          npx playwright install --with-deps chromium

      - name: Read currently deployed stamp (safe)
        id: deployed
        shell: bash
        run: |
          set -euo pipefail
          PAGES_URL="https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/schedule.json"
          # Do not echo PAGES_URL to avoid leaking repo naming changes in forks; it is public anyway, but keep logs minimal.
          DEPLOYED_UPDATE=""
          if command -v curl >/dev/null 2>&1; then
            DEPLOYED_UPDATE="$(curl -fsSL "$PAGES_URL" | node -e 'let s="";process.stdin.on("data",d=>s+=d);process.stdin.on("end",()=>{try{const j=JSON.parse(s);process.stdout.write(String(j.update||""));}catch{process.stdout.write("");}})')" || true
          fi
          echo "update=$DEPLOYED_UPDATE" >> "$GITHUB_OUTPUT"

      - name: Save npm cache
        if: steps.npm-cache.outputs.cache-hit != 'true'
        uses: actions/cache/save@v4
        with:
          path: ~/.npm
          key: ${{ runner.os }}-npm-node20-playwright-${{ steps.pw.outputs.version }}

      - name: Save Playwright browsers
        if: steps.pw-cache.outputs.cache-hit != 'true'
        uses: actions/cache/save@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-ms-playwright-${{ steps.pw.outputs.version }}
          
      - name: Run scraper
        env:
          TARGET_URL: ${{ secrets.TARGET_URL }}
          DATA_VARIABLE_NAME: ${{ secrets.DATA_VARIABLE_NAME }}
        run: node scraper.js

      - name: Scrape summary (redacted)
        shell: bash
        run: |
          set -euo pipefail
          node - <<'NODE'
          const fs = require('fs');
          const path = require('path');
          const metaPath = path.join(process.cwd(), 'scraped-data', 'latest-metadata.json');
          const schedPath = path.join(process.cwd(), 'scraped-data', 'schedule.json');
          const meta = JSON.parse(fs.readFileSync(metaPath, 'utf8'));
          const schedule = JSON.parse(fs.readFileSync(schedPath, 'utf8'));
          const todayKey = schedule && schedule.today ? String(schedule.today) : '';
          const groups = schedule && schedule.data && todayKey && schedule.data[todayKey] ? Object.keys(schedule.data[todayKey]) : [];
          console.log('Scrape OK:', Boolean(meta.success));
          console.log('Schedule update stamp:', schedule.update || '');
          console.log('Scraped at:', schedule.scraped_at || '');
          console.log('Today key:', todayKey);
          console.log('Group count (today):', groups.length);
          NODE
          echo "Previously deployed update stamp: ${{ steps.deployed.outputs.update }}"
          
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: ./scraped-data
          
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

      - name: Verify GitHub Pages updated (bullet-proof)
        shell: bash
        run: |
          set -euo pipefail

          EXPECTED_UPDATE="$(node -e 'const fs=require("fs");const j=JSON.parse(fs.readFileSync("scraped-data/schedule.json","utf8"));process.stdout.write(String(j.update||""));')"
          if [[ -z "$EXPECTED_UPDATE" ]]; then
            echo "ERROR: expected update stamp is empty (scraped-data/schedule.json)." >&2
            exit 1
          fi

          # Prefer the URL returned by the deployment step; fall back to the conventional Pages URL.
          PAGE_URL="${{ steps.deployment.outputs.page_url }}"
          if [[ -z "$PAGE_URL" ]]; then
            PAGE_URL="https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/"
          fi
          # Ensure trailing slash.
          [[ "$PAGE_URL" != */ ]] && PAGE_URL="$PAGE_URL/"
          TARGET_JSON_URL="${PAGE_URL}schedule.json"

          echo "Expected update stamp: $EXPECTED_UPDATE"
          echo "Checking: $TARGET_JSON_URL"

          # GitHub Pages sits behind a CDN; even after 'deploy-pages' reports success,
          # the edge may serve stale content briefly. Retry with cache-busting.
          LAST_SEEN=""
          for i in $(seq 1 60); do
            CB="_cb=${GITHUB_RUN_ID}-${GITHUB_RUN_ATTEMPT}-${i}"
            SEEN=""
            if command -v curl >/dev/null 2>&1; then
              SEEN="$(curl -fsSL \
                -H 'Cache-Control: no-cache' \
                -H 'Pragma: no-cache' \
                "${TARGET_JSON_URL}?${CB}" \
                | node -e 'let s="";process.stdin.on("data",d=>s+=d);process.stdin.on("end",()=>{try{const j=JSON.parse(s);process.stdout.write(String(j.update||""));}catch{process.stdout.write("");}})'
              )" || true
            fi

            if [[ -n "$SEEN" ]]; then
              LAST_SEEN="$SEEN"
            fi

            if [[ "$SEEN" == "$EXPECTED_UPDATE" ]]; then
              echo "OK: GitHub Pages now serves the new schedule.json (attempt $i)."
              exit 0
            fi

            echo "Not updated yet (attempt $i): seen='${SEEN:-<empty>}'"
            sleep 5
          done

          echo "ERROR: GitHub Pages did not serve the expected update stamp in time." >&2
          echo "Expected: $EXPECTED_UPDATE" >&2
          echo "Last seen: ${LAST_SEEN:-<empty>}" >&2
          exit 1
